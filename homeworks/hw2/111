{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFaf7VErZ1Bf"
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3g3k3W-qfAv"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vsESFZylO6O"
   },
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hrdfpmv9nMpw",
    "outputId": "50535420-4ddd-486f-dd94-491d4799850f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: markitdown[pdf] in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
      "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.6.3)\n",
      "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (1.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
      "Requirement already satisfied: pdfminer-six>=20251230 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (20251230)\n",
      "Requirement already satisfied: pdfplumber>=0.11.9 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.11.9)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.24.2)\n",
      "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (5.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
      "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
      "Requirement already satisfied: langchain_mcp_adapters in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (4.2.1)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.15)\n",
      "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.64.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
      "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.23.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.13.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.6)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.1)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests PyPDF2 gdown\n",
    "!pip install 'markitdown[pdf]'\n",
    "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUav-7KdaY_W"
   },
   "source": [
    "## Setup your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
    "\n",
    "\n",
    "1.   Look for the key icon on the left panel of your colab.\n",
    "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
    "3. Copy your key to `Value`.\n",
    "\n",
    "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ueILmCPHci9v"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
    "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l8Xx7qQcfEjN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRbStil_qkQc"
   },
   "source": [
    "# Download sample CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCENjOq6owDd"
   },
   "source": [
    "## Downloading sample_cv.pdf\n",
    "The codes below download the sample CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kCCp8DwPF4L",
    "outputId": "13ca05ae-b1de-420c-fb6d-876cd40a30de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
      "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
      "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
      "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
      "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
      "To: /content/downloaded_cvs/CV_1.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 38.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
      "To: /content/downloaded_cvs/CV_2.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 63.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
      "To: /content/downloaded_cvs/CV_3.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 11.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
      "To: /content/downloaded_cvs/CV_4.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 20.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
      "To: /content/downloaded_cvs/CV_5.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 11.1MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['downloaded_cvs/CV_1.pdf',\n",
       " 'downloaded_cvs/CV_2.pdf',\n",
       " 'downloaded_cvs/CV_3.pdf',\n",
       " 'downloaded_cvs/CV_4.pdf',\n",
       " 'downloaded_cvs/CV_5.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
    "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
    "\n",
    "output_dir = \"downloaded_cvs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "gdown.download_folder(\n",
    "    url=folder_url,\n",
    "    output=output_dir,\n",
    "    quiet=False,\n",
    "    use_cookies=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2akmVn9LODIu",
    "outputId": "f7721019-cd23-481a-f005-4c2b2f266539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“„ CV_1.pdf\n",
      "================================================================================\n",
      "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
      "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
      "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
      "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
      "Experience\n",
      "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
      "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
      "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
      "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
      "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
      "â€¢ Applied analytical and problem-solving skills in production systems.\n",
      "Education\n",
      "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
      "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
      "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
      "Skills\n",
      "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
      "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“„ CV_2.pdf\n",
      "================================================================================\n",
      "| Minh | Pham |     |     |     |     |     |\n",
      "| ---- | ---- | --- | --- | --- | --- | --- |\n",
      "Design Professional\n",
      "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
      "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
      "| Professional | Experience       |          |               |        |              |                |\n",
      "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
      "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
      "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
      "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
      "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
      "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
      "â€¢ Conducted market and product analysis to support decision-making.\n",
      "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
      "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
      "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
      "Education\n",
      "| BSc in         | Design  |      |     |     |     | 2011 |\n",
      "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
      "| The University | of Hong | Kong |     |     |     |      |\n",
      "Skills\n",
      "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
      "| ------- | ------ | --- | --- | --- | --- | --- |\n",
      "â€¢ Prototyping\n",
      "| â€¢ Graphic | Design |     |     |     |     |     |\n",
      "| --------- | ------ | --- | --- | --- | --- | --- |\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“„ CV_3.pdf\n",
      "================================================================================\n",
      "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
      "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
      "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
      "| Professional | Experience   |           |     |     |     |                   |\n",
      "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
      "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
      "projects.\n",
      "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
      "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
      "dations.\n",
      "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
      "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
      "|     |     | sional services | environment. |                  |          |           |\n",
      "Education\n",
      "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
      "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
      "|      |     | University        | of Tokyo |     |     |     |\n",
      "Skills\n",
      "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
      "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
      "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“„ CV_4.pdf\n",
      "================================================================================\n",
      "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
      "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
      "Legal Professional\n",
      "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
      "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
      "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
      "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
      "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
      "cal teams.\n",
      "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
      "plex systems.\n",
      "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
      "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
      "nance.\n",
      "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
      "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
      "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
      "panies.\n",
      "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
      "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
      "management.\n",
      "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
      "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
      "ers.\n",
      "Education\n",
      "2021\n",
      "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
      "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
      "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
      "Skills\n",
      "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
      "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
      "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“„ CV_5.pdf\n",
      "================================================================================\n",
      "| Rahul | Sharma |     |     |     |     |     |     |\n",
      "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
      "AI Professional\n",
      "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
      "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
      "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
      "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
      "|            |             |             |            | EY           |               |                | Current       |\n",
      "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
      "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
      "|            |             |             |            | enterprise   | clients.      |                |               |\n",
      "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
      "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
      "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
      "Consultant\n",
      "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
      "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
      "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
      "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
      "|              |     |       |     | early-stage | companies.  |          |             |\n",
      "â€¢ PyTorch\n",
      "Senior Analyst\n",
      "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
      "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
      "â€¢ Python\n",
      "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
      "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
      "evaluation.\n",
      "Lead Scientist\n",
      "Education\n",
      "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
      "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
      "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
      "| University | of Tokyo |     |     |            |                    |                |     |\n",
      "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
      "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
      "1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "#  Load and display all CV PDFs in order\n",
    "# =====================================================\n",
    "import os\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "cv_dir = \"downloaded_cvs\"\n",
    "\n",
    "# Initialize MarkItDown\n",
    "md = MarkItDown(enable_plugins=False)\n",
    "\n",
    "# Collect and sort PDFs numerically\n",
    "pdf_files = sorted(\n",
    "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
    "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
    ")\n",
    "\n",
    "all_cvs = []\n",
    "\n",
    "for pdf_name in pdf_files:\n",
    "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
    "    result = md.convert(pdf_path)\n",
    "\n",
    "    all_cvs.append({\n",
    "        \"file\": pdf_name,\n",
    "        \"text\": result.text_content\n",
    "    })\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ðŸ“„ {pdf_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result.text_content)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA2GvPWTQFt9"
   },
   "source": [
    "# Connect to our MCP server\n",
    "\n",
    "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
    "\n",
    "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mbkH9xHXfmK"
   },
   "source": [
    "## Check which tools that the MCP server provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6h0311KbN9A3",
    "outputId": "85c0ba03-3932-4750-fda6-d21817514f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_facebook_users\n",
      "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
      "\n",
      "Args:\n",
      "    q: Search query string (case-insensitive, matches any part of display name)\n",
      "       Examples: \"John\", \"john smith\", \"Smith\"\n",
      "    limit: Maximum number of results to return (default: 20, max: 20)\n",
      "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
      "\n",
      "Returns:\n",
      "    List of user dictionaries, each containing:\n",
      "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
      "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
      "    - city (str): Current city of residence\n",
      "    - country (str): Country of residence\n",
      "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
      "    \n",
      "    Returns empty list [] if no matches found.\n",
      "\n",
      "Example:\n",
      "    search_facebook_users(\"Alex Chan\", limit=5)\n",
      "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
      "    \n",
      "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
      "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
      "\n",
      "Use case:\n",
      "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
      "    personal information, location, and social connections. Handles typos and variations.\n",
      "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_facebook_profile\n",
      "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
      "\n",
      "Args:\n",
      "    user_id: Facebook user ID obtained from search_facebook_users()\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - id (int): Facebook user ID\n",
      "    - display_name (str): Public display name (may be nickname)\n",
      "    - original_name (str): Original/legal name from LinkedIn\n",
      "    - city (str): Current city\n",
      "    - country (str): Current country\n",
      "    - hometown (str|None): City/region where user grew up\n",
      "    - bio (str): Personal biography/interests\n",
      "    - status (str|None): Relationship status (Single, Married, etc.)\n",
      "    - education (str|None): Highest education level\n",
      "    - current_job (str|None): Current job title\n",
      "    - current_company (str|None): Current employer\n",
      "    - interests (str): Comma-separated hobbies/interests\n",
      "    - friends (List[int]): List of friend user IDs\n",
      "    - posts (List[dict]): Recent posts with id and content\n",
      "    \n",
      "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
      "\n",
      "Example:\n",
      "    get_facebook_profile(123)\n",
      "    â†’ {\n",
      "        \"id\": 123,\n",
      "        \"display_name\": \"Sam Chan\",\n",
      "        \"original_name\": \"Alex Chan\",\n",
      "        \"city\": \"Hong Kong\",\n",
      "        \"hometown\": \"Kowloon\",\n",
      "        \"bio\": \"Software professional | Photography enthusiast\",\n",
      "        \"status\": \"Married\",\n",
      "        \"current_job\": \"Senior Engineer\",\n",
      "        \"current_company\": \"Google\",\n",
      "        \"friends\": [124, 125, 126],\n",
      "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Verify candidate's personal details, check for name discrepancies,\n",
      "    validate current employment, and assess social connections.\n",
      "{'user_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_facebook_mutual_friends\n",
      "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
      "\n",
      "Args:\n",
      "    user_id_1: First Facebook user ID\n",
      "    user_id_2: Second Facebook user ID\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - user_1_id (int): First user's ID\n",
      "    - user_2_id (int): Second user's ID\n",
      "    - mutual_friends (List[int]): List of shared friend IDs\n",
      "    - mutual_count (int): Number of mutual friends\n",
      "    \n",
      "    Returns {\"error\": \"...\"} if either user not found.\n",
      "\n",
      "Example:\n",
      "    get_facebook_mutual_friends(123, 456)\n",
      "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
      "\n",
      "Use case:\n",
      "    Verify professional or personal relationships claimed in CV/references.\n",
      "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "search_linkedin_people\n",
      "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
      "\n",
      "Args:\n",
      "    q: Search query (matches name, headline, summary, or skill names)\n",
      "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
      "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
      "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
      "    industry: Filter by industry (optional, case-insensitive)\n",
      "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
      "    limit: Maximum results to return (default: 20, max: 20)\n",
      "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
      "\n",
      "Returns:\n",
      "    List of profile dictionaries, each containing:\n",
      "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
      "    - name (str): Full name\n",
      "    - headline (str): Professional headline/title\n",
      "    - industry (str): Industry sector\n",
      "    - location (str): \"City, Country\" format\n",
      "    - years_experience (int): Total years of work experience\n",
      "    - match_type (str): \"exact\" or \"fuzzy\"\n",
      "    \n",
      "    Returns empty list [] if no matches found.\n",
      "\n",
      "Example:\n",
      "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
      "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
      "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
      "    \n",
      "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
      "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
      "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
      "\n",
      "Use case:\n",
      "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
      "    Use location filter to narrow down results when common names exist. Handles typos.\n",
      "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_linkedin_profile\n",
      "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
      "\n",
      "Args:\n",
      "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - id (int): LinkedIn profile ID\n",
      "    - name (str): Full name\n",
      "    - headline (str): Professional headline\n",
      "    - city (str): Current city\n",
      "    - country (str): Current country\n",
      "    - industry (str): Primary industry\n",
      "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
      "    - years_experience (int): Total years of professional experience\n",
      "    - summary (str): Professional summary/bio\n",
      "    \n",
      "    - skills (List[dict]): Each containing:\n",
      "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
      "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
      "    \n",
      "    - experience (List[dict]): Work history, each containing:\n",
      "        * company (str): Employer name\n",
      "        * title (str): Job title\n",
      "        * seniority (str): Level (junior, mid, senior)\n",
      "        * start_year (int): Employment start year\n",
      "        * end_year (int|None): Employment end year (None if current)\n",
      "        * is_current (bool): Whether currently employed here\n",
      "    \n",
      "    - education (List[dict]): Academic history, each containing:\n",
      "        * school (str): Institution name\n",
      "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
      "        * field (str): Field of study\n",
      "        * start_year (int): Start year\n",
      "        * end_year (int): Graduation year\n",
      "    \n",
      "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
      "\n",
      "Example:\n",
      "    get_linkedin_profile(456)\n",
      "    â†’ {\n",
      "        \"id\": 456,\n",
      "        \"name\": \"Alex Chan\",\n",
      "        \"headline\": \"Senior Software Engineer\",\n",
      "        \"years_experience\": 8,\n",
      "        \"skills\": [\n",
      "            {\"name\": \"Python\", \"proficiency\": 5},\n",
      "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
      "        ],\n",
      "        \"experience\": [\n",
      "            {\n",
      "                \"company\": \"Google\",\n",
      "                \"title\": \"Senior Engineer\",\n",
      "                \"seniority\": \"senior\",\n",
      "                \"start_year\": 2020,\n",
      "                \"end_year\": None,\n",
      "                \"is_current\": True\n",
      "            }\n",
      "        ],\n",
      "        \"education\": [\n",
      "            {\n",
      "                \"school\": \"HKUST\",\n",
      "                \"degree\": \"BSc\",\n",
      "                \"field\": \"Computer Science\",\n",
      "                \"start_year\": 2010,\n",
      "                \"end_year\": 2014\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Primary tool for CV verification - compare claimed experience, education,\n",
      "    skills, and employment dates against LinkedIn ground truth.\n",
      "{'person_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_linkedin_interactions\n",
      "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
      "\n",
      "Args:\n",
      "    person_id: LinkedIn profile ID\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - profile_id (int): The person's LinkedIn ID\n",
      "    - post_count (int): Number of posts made\n",
      "    - total_likes (int): Total likes received across all posts\n",
      "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
      "    - engagement_score (float): Likes per post ratio\n",
      "    \n",
      "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
      "\n",
      "Example:\n",
      "    get_linkedin_interactions(456)\n",
      "    â†’ {\n",
      "        \"profile_id\": 456,\n",
      "        \"post_count\": 10,\n",
      "        \"total_likes\": 150,\n",
      "        \"liked_by\": [123, 124, 125],\n",
      "        \"engagement_score\": 15.0\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Assess professional network strength and content engagement.\n",
      "    Verify connections to claimed colleagues or industry peers.\n",
      "{'person_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient({\n",
    "    \"social_graph\": {\n",
    "        \"transport\": \"http\",\n",
    "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
    "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
    "    }\n",
    "})\n",
    "\n",
    "mcp_tools = await client.get_tools()\n",
    "for tool in mcp_tools:\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(tool.args)\n",
    "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABoe2-qfXl7r"
   },
   "source": [
    "## A simple agent using tools from the MCP server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtTjwFKhTKn3",
    "outputId": "b75af704-fc97-4309-cd45-59872d23df89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'name': 'search_facebook_users', 'arguments': '{\"q\": \"Alice\"}'}, '__gemini_function_call_thought_signatures__': {'7fb50ef0-5c05-45a1-976e-3b20a89663b8': 'Cs8DAb4+9vv4aKsy+vGqHCM8z7y2JX2ckk3qem32tHVaqRCaTJeVZJD3hFB/pdAEXw2uiWmjXuLgfBdVJg07DmasFlHgZSHxfzDMtBwj8EKRVBduXYQtVVoO8shSMA40QFSmYacu26wa8zq//TDjO8fi5wPDvmh3Lp31WCIUZdceDWWYYFa8jhkDcwghmZM3P9/UGtF0kOvEkpt09U6A88HxTQEtTRC4LvAiMNHjb9LS8W6Cz9swjx5CNkWC+Zc0rZKNT/nrgohxn6Az8pqGh8C9ImZvLUR0cOcLFjwfG08bXlmyelSJQEvO304evAk2G4iBUDd0wRdrY+mjSWqEJJTjRLyYU5CmT0uh7mc8/lQRyo1uoC8NPdpEtr5kaxEwZY/emjGp+gzcLbeo+65ZgbZ9GPcKztVpD5FGTTLHFsfFbiboXtbskyzpEYigpFLdZGC1TiisCaquJ2KYf3w8MXS++/5XsIhBYbjigU2z+2eY0CNWxi4txnJFWaubdyPa5Xiw/TzZV4a3z/7mvsRhSmzk12bQnuJcVysWbnUkFAM2cQEcGRwTGp2MUcoUBggID+l2TLpq8f/Q/vqx/XKazOq9eccJn4BVr36LBiXqD8sFvQ=='}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c9f86-4eb4-7440-b2d4-2082e80574b5-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': '7fb50ef0-5c05-45a1-976e-3b20a89663b8', 'type': 'tool_call'}, {'name': 'search_facebook_users', 'args': {'q': 'Alice'}, 'id': '882f2f5f-a001-4358-b5de-7eca1f4cdb68', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 2852, 'output_tokens': 141, 'total_tokens': 2993, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 108}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Define a local tool\n",
    "# ---------------------------\n",
    "@tool\n",
    "def say_hello(name: str) -> str:\n",
    "    \"\"\"Say hello to a person by name.\"\"\"\n",
    "    return f\"Hello, {name}! ðŸ‘‹\"\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load MCP tools + merge\n",
    "# ---------------------------\n",
    "client = MultiServerMCPClient({\n",
    "    \"social_graph\": {\n",
    "        \"transport\": \"http\",\n",
    "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
    "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
    "    }\n",
    "})\n",
    "\n",
    "mcp_tools = await client.get_tools()\n",
    "tools = mcp_tools + [say_hello]\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
    "# ---------------------------\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\", # Changed from \"gemini-2.0-flash\"\n",
    "    google_api_key=GEMINI_VERTEX_API_KEY,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# DEEPSEEK_API_KEY = userdata.get(\"DEEPSEEK_API_KEY\")\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"deepseek-chat\",          # or \"deepseek-reasoner\"\n",
    "#     api_key=DEEPSEEK_API_KEY,\n",
    "#     base_url=\"https://api.deepseek.com/v1\",\n",
    "#     temperature=0,\n",
    "# )\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Single-step invocation\n",
    "# ---------------------------\n",
    "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
    "\n",
    "response = llm_with_tools.invoke([\n",
    "    HumanMessage(content=query)\n",
    "])\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhLeoXGrqesW",
    "outputId": "0562924b-842c-49d6-932a-fca511a0310e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
       "  'id': 'lc_6c6e70db-8e62-4e8b-b61d-515c2fc3893e'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block provides you some tests to get faminilar with our MCP server\n",
    "\n",
    "# # Test 1: Search Facebook users (exact match)\n",
    "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
    "\n",
    "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
    "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
    "\n",
    "# # Test 3: Get Facebook profile\n",
    "# await tools[1].ainvoke({'user_id': 123})\n",
    "\n",
    "# # Test 4: Get Facebook mutual friends\n",
    "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
    "\n",
    "# # Test 5: Search LinkedIn people (exact match)\n",
    "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
    "\n",
    "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
    "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
    "\n",
    "# # Test 7: Get LinkedIn profile\n",
    "# await tools[4].ainvoke({'person_id': 456})\n",
    "\n",
    "# Test 8: Get LinkedIn interactions\n",
    "await tools[5].ainvoke({'person_id': 456})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqO99iOlq6mc"
   },
   "source": [
    "# Evaluation code\n",
    "\n",
    "In the test phase, you will be given 5 CV files with fixed names:\n",
    "\n",
    "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
    "\n",
    "Your system must process these CVs and output a list of 5 scores,\n",
    "one score per CV, in the same order:\n",
    "\n",
    "    scores = [s1, s2, s3, s4, s5]\n",
    "\n",
    "Each score must be a float in the range [0, 1], representing the\n",
    "reliability or confidence that the CV is valid (or meets the task criteria).\n",
    "\n",
    "The ground-truth labels are binary:\n",
    "\n",
    "    groundtruth = [0 or 1, ..., 0 or 1]\n",
    "\n",
    "Each CV is evaluated independently using a threshold of 0.5:\n",
    "\n",
    "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
    "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
    "- Otherwise â†’ No credit\n",
    "\n",
    "In other words, 0.5 is the decision threshold.\n",
    "\n",
    "- Each CV contributes equally.\n",
    "- Final score = (number of correct decisions) / 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0TtL07airIqz"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "#  Evaluation code\n",
    "# =====================================================\n",
    "\n",
    "def evaluate(scores, groundtruth, threshold=0.5):\n",
    "    \"\"\"\n",
    "    scores: list of floats in [0, 1], length = 5\n",
    "    groundtruth: list of ints (0 or 1), length = 5\n",
    "    \"\"\"\n",
    "    assert len(scores) == 5\n",
    "    assert len(groundtruth) == 5\n",
    "\n",
    "    correct = 0\n",
    "    decisions = []\n",
    "\n",
    "    for s, gt in zip(scores, groundtruth):\n",
    "        pred = 1 if s > threshold else 0\n",
    "        decisions.append(pred)\n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "\n",
    "    final_score = correct / len(scores)\n",
    "\n",
    "    return {\n",
    "        \"decisions\": decisions,\n",
    "        \"correct\": correct,\n",
    "        \"total\": len(scores),\n",
    "        \"final_score\": final_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzjWo3shcu-V",
    "outputId": "76d42192-79fc-4ca6-bf27-ab5c1f4c5eae"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3933/1048926920.py:31: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(llm, mcp_tools)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Verifying: CV_1.pdf\n",
      "============================================================\n",
      "\n",
      "Agent response (last message):\n",
      "```json\n",
      "{\n",
      "  \"score\": 0.3,\n",
      "  \"discrepancies\": [\n",
      "    \"Company Mismatch: The CV claims the current employer is ByteDance, but the Facebook profile lists the current company as Traveloka.\",\n",
      "    \"Job Title Mismatch: The CV claims the current job title is 'Engineer', but the Facebook profile lists the current job as 'Scientist'.\",\n",
      "    \"Employment Status Mismatch: The CV states the employment at ByteDance is '2020 â€“ Present', but the LinkedIn profile indicates this job is not current and the candidate's overall status is 'student'.\",\n",
      "    \"Internal Inconsistency: Both the CV and LinkedIn show a major conflict between the claimed job title ('Engineer') and the candidate's education ('BSc in Marketing') and skills ('Content Creation', 'SEO', 'Social Media').\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "â†’ Final score for CV_1.pdf: 0.3\n",
      "â†’ Discrepancies: ['Company Mismatch: The CV claims the current employer is ByteDance, but the Facebook profile lists the current company as Traveloka.', \"Job Title Mismatch: The CV claims the current job title is 'Engineer', but the Facebook profile lists the current job as 'Scientist'.\", \"Employment Status Mismatch: The CV states the employment at ByteDance is '2020 â€“ Present', but the LinkedIn profile indicates this job is not current and the candidate's overall status is 'student'.\", \"Internal Inconsistency: Both the CV and LinkedIn show a major conflict between the claimed job title ('Engineer') and the candidate's education ('BSc in Marketing') and skills ('Content Creation', 'SEO', 'Social Media').\"]\n",
      "\n",
      "============================================================\n",
      "Verifying: CV_2.pdf\n",
      "============================================================\n",
      "\n",
      "Agent response (last message):\n",
      "There are significant and numerous inconsistencies between the CV and the information found on the most plausible LinkedIn and Facebook profiles for \"Minh Pham\" in Hong Kong.\n",
      "\n",
      "**Analysis & Discrepancies:**\n",
      "\n",
      "1.  **Current Employment Mismatch:** The CV claims the candidate is a \"Manager\" at \"BCG\" since 2022. Both the LinkedIn and Facebook profiles state the candidate's role is \"Engineer\" at \"Grab\".\n",
      "2.  **Employment History Mismatch:** The CV lists past employment as an \"Analyst\" at \"Tencent\" (2013-2017). The LinkedIn profile shows a role as an \"Engineer\" at \"Grab\" starting in 2015, with no mention of Tencent or BCG.\n",
      "3.  **Date Discrepancy & Overlap:** The LinkedIn profile's start year at Grab (2015) conflicts with the CV's claim of working at Tencent from 2013 to 2017. This suggests an impossible overlap where the candidate would be working at both companies simultaneously.\n",
      "4.  **University Mismatch:** The CV states the candidate graduated from \"The University of Hong Kong\", but the LinkedIn profile lists \"Oxford\".\n",
      "5.  **Degree Mismatch:** The CV claims a \"BSc in Design\", whereas the LinkedIn profile claims an \"MBA\" in \"Consulting\". The Facebook profile generically lists \"Master's Degree\", which is inconsistent with the CV's \"BSc\".\n",
      "6.  **Graduation Year Mismatch:** The CV states a graduation year of 2011, while the LinkedIn profile indicates 2010.\n",
      "7.  **Skills Mismatch:** The CV lists design-focused skills (UI/UX, Prototyping, Graphic Design). The LinkedIn profile lists consulting-focused skills (PowerPoint, Data Analysis, Problem Solving). There is no overlap.\n",
      "\n",
      "A total of **7 major discrepancies** were found across employment, education, and skills. The information presented in the CV appears to be almost entirely different from the public-facing professional profiles.\n",
      "```json\n",
      "{\n",
      "  \"score\": 0.1,\n",
      "  \"discrepancies\": [\n",
      "    \"Current company does not match CV (CV: BCG, LinkedIn: Grab).\",\n",
      "    \"Current job title does not match CV (CV: Manager, LinkedIn: Engineer).\",\n",
      "    \"Employment history is inconsistent (CV lists Tencent, LinkedIn lists Grab).\",\n",
      "    \"Employment dates conflict between the CV and LinkedIn, with an impossible overlap from 2015-2017.\",\n",
      "    \"Education institution does not match (CV: The University of Hong Kong, LinkedIn: Oxford).\",\n",
      "    \"Degree does not match (CV: BSc in Design, LinkedIn: MBA in Consulting).\",\n",
      "    \"Claimed skills do not align with LinkedIn profile (Design skills vs. Consulting skills).\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "â†’ Final score for CV_2.pdf: 0.1\n",
      "â†’ Discrepancies: ['Current company does not match CV (CV: BCG, LinkedIn: Grab).', 'Current job title does not match CV (CV: Manager, LinkedIn: Engineer).', 'Employment history is inconsistent (CV lists Tencent, LinkedIn lists Grab).', 'Employment dates conflict between the CV and LinkedIn, with an impossible overlap from 2015-2017.', 'Education institution does not match (CV: The University of Hong Kong, LinkedIn: Oxford).', 'Degree does not match (CV: BSc in Design, LinkedIn: MBA in Consulting).', 'Claimed skills do not align with LinkedIn profile (Design skills vs. Consulting skills).']\n",
      "\n",
      "============================================================\n",
      "Verifying: CV_3.pdf\n",
      "============================================================\n",
      "\n",
      "Agent response (last message):\n",
      "{\n",
      "  \"score\": 0.4,\n",
      "  \"discrepancies\": [\n",
      "    \"Internal CV Inconsistency: The candidate claims to have started working as an Engineer at PwC in 2013, but their graduation from the University of Tokyo is listed as 2015. It is highly improbable to hold an engineering role for two years before completing a bachelor's degree.\",\n",
      "    \"Employment Status Mismatch: The CV states the role at PwC is from '2013 â€“ Present', but the corresponding LinkedIn profile indicates the role is not current.\",\n",
      "    \"Location Mismatch: The CV lists Sydney as the candidate's hometown, but their Facebook profile states their hometown is Munich.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "â†’ Final score for CV_3.pdf: 0.4\n",
      "â†’ Discrepancies: [\"Internal CV Inconsistency: The candidate claims to have started working as an Engineer at PwC in 2013, but their graduation from the University of Tokyo is listed as 2015. It is highly improbable to hold an engineering role for two years before completing a bachelor's degree.\", \"Employment Status Mismatch: The CV states the role at PwC is from '2013 â€“ Present', but the corresponding LinkedIn profile indicates the role is not current.\", \"Location Mismatch: The CV lists Sydney as the candidate's hometown, but their Facebook profile states their hometown is Munich.\"]\n",
      "\n",
      "============================================================\n",
      "Verifying: CV_4.pdf\n",
      "============================================================\n",
      "\n",
      "Agent response (last message):\n",
      "```json\n",
      "{\n",
      "  \"score\": 0.1,\n",
      "  \"discrepancies\": [\n",
      "    \"Internal CV Inconsistency: Employment at Microsoft listed with a future end date (2027).\",\n",
      "    \"Internal CV Inconsistency: Overlapping employment dates between Microsoft (2021-2027) and StartupXYZ (2020-2023).\",\n",
      "    \"Company Mismatch: CV claims work at 'Microsoft' and 'StartupXYZ', but LinkedIn profile shows 'Tencent' and Facebook profile shows 'Shopee'.\",\n",
      "    \"Job Title Mismatch: CV claims titles of 'Senior Engineer' and 'Consultant', but LinkedIn profile shows 'Analyst' and Facebook shows 'Manager'.\",\n",
      "    \"Education Mismatch (School): CV claims PhD from 'Tsinghua University', but LinkedIn profile lists MSc from 'Stanford'.\",\n",
      "    \"Education Mismatch (Degree & Year): CV claims a 'PhD' in 2021, while LinkedIn shows an 'MSc' completed in 2010.\",\n",
      "    \"Date Discrepancy: Employment dates on the CV (2021-2027, 2020-2023) do not match the LinkedIn profile's timeline (2019-2023).\",\n",
      "    \"Skills Mismatch: CV lists highly technical skills ('Web3', 'Machine Learning', 'Quantum Computing') which are absent from the LinkedIn profile.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "â†’ Final score for CV_4.pdf: 0.1\n",
      "â†’ Discrepancies: ['Internal CV Inconsistency: Employment at Microsoft listed with a future end date (2027).', 'Internal CV Inconsistency: Overlapping employment dates between Microsoft (2021-2027) and StartupXYZ (2020-2023).', \"Company Mismatch: CV claims work at 'Microsoft' and 'StartupXYZ', but LinkedIn profile shows 'Tencent' and Facebook profile shows 'Shopee'.\", \"Job Title Mismatch: CV claims titles of 'Senior Engineer' and 'Consultant', but LinkedIn profile shows 'Analyst' and Facebook shows 'Manager'.\", \"Education Mismatch (School): CV claims PhD from 'Tsinghua University', but LinkedIn profile lists MSc from 'Stanford'.\", \"Education Mismatch (Degree & Year): CV claims a 'PhD' in 2021, while LinkedIn shows an 'MSc' completed in 2010.\", \"Date Discrepancy: Employment dates on the CV (2021-2027, 2020-2023) do not match the LinkedIn profile's timeline (2019-2023).\", \"Skills Mismatch: CV lists highly technical skills ('Web3', 'Machine Learning', 'Quantum Computing') which are absent from the LinkedIn profile.\"]\n",
      "\n",
      "============================================================\n",
      "Verifying: CV_5.pdf\n",
      "============================================================\n",
      "\n",
      "Agent response (last message):\n",
      "There are significant and numerous inconsistencies between the CV, the candidate's LinkedIn profile, and internal claims within the CV itself.\n",
      "\n",
      "### Internal CV Discrepancies:\n",
      "1.  **Impossible Overlapping Jobs**: The CV lists a role at **DataForge (2016 â€“ Present)** and another as **Senior Engineer at EY (Current)**. A person cannot hold two separate, current full-time positions.\n",
      "2.  **Contradictory Timelines**: The role at **UrbanFlow (2010 â€“ 2017)** overlaps with the role at **DataForge (2016 â€“ Present)**.\n",
      "3.  **Illogical Career Progression**: The CV claims the candidate began a **Lead Scientist** role in 2010, two years *before* their listed PhD graduation in 2012. This is highly improbable.\n",
      "\n",
      "### CV vs. LinkedIn & Facebook Discrepancies:\n",
      "4.  **Current Company Mismatch**: The CV states the current employer is **EY**. Both LinkedIn and Facebook state the current employer is **PwC**.\n",
      "5.  **Current Job Title Mismatch**: The CV claims the title is **Senior Engineer**. Both LinkedIn and Facebook state the title is **Manager**.\n",
      "6.  **Employment History Fabricated**: The CV lists roles at **StartupXYZ**, **DataForge**, and **UrbanFlow**. None of these companies appear on the LinkedIn profile's work history.\n",
      "7.  **Date Mismatches**: The entire timeline of the CV is incorrect. LinkedIn shows employment at PwC starting in 2010, which contradicts all four roles listed on the CV.\n",
      "8.  **Educational Institution Mismatch**: The CV claims a PhD from the **University of Tokyo**. The LinkedIn profile lists a PhD from **KAIST**.\n",
      "9.  **Graduation Year Mismatch**: The CV claims a graduation year of **2012**. LinkedIn states the graduation year was **2006**.\n",
      "10. **Location Mismatch**: The CV lists **Singapore** as the hometown, whereas Facebook lists **London**.\n",
      "11. **Skills Mismatch**: The CV lists **PyTorch** as a skill, which is not mentioned on the LinkedIn profile.\n",
      "\n",
      "A total of **11** major discrepancies were found when comparing the CV to social media profiles, in addition to **3** major internal inconsistencies within the CV itself. The evidence strongly suggests the CV is largely fabricated.\n",
      "```json\n",
      "{\n",
      "  \"score\": 0.1,\n",
      "  \"discrepancies\": [\n",
      "    \"CV claims current role is 'Senior Engineer at EY', but LinkedIn and Facebook state 'Manager at PwC'.\",\n",
      "    \"The entire work history on the CV (StartupXYZ, DataForge, UrbanFlow) is absent from the LinkedIn profile.\",\n",
      "    \"CV claims a PhD from 'University of Tokyo' in 2012, but LinkedIn shows a PhD from 'KAIST' in 2006.\",\n",
      "    \"The CV contains impossible overlapping timelines, with two 'current' jobs listed (EY and DataForge).\",\n",
      "    \"The CV's timeline is illogical, claiming a 'Lead Scientist' role started two years before the listed PhD graduation date.\",\n",
      "    \"CV lists Singapore as hometown, which contradicts the Facebook profile.\",\n",
      "    \"The employment dates for all four positions listed on the CV are contradicted by the LinkedIn profile.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "â†’ Final score for CV_5.pdf: 0.1\n",
      "â†’ Discrepancies: [\"CV claims current role is 'Senior Engineer at EY', but LinkedIn and Facebook state 'Manager at PwC'.\", 'The entire work history on the CV (StartupXYZ, DataForge, UrbanFlow) is absent from the LinkedIn profile.', \"CV claims a PhD from 'University of Tokyo' in 2012, but LinkedIn shows a PhD from 'KAIST' in 2006.\", \"The CV contains impossible overlapping timelines, with two 'current' jobs listed (EY and DataForge).\", \"The CV's timeline is illogical, claiming a 'Lead Scientist' role started two years before the listed PhD graduation date.\", 'CV lists Singapore as hometown, which contradicts the Facebook profile.', 'The employment dates for all four positions listed on the CV are contradicted by the LinkedIn profile.']\n",
      "\n",
      "\n",
      "============================================================\n",
      "VERIFICATION COMPLETE\n",
      "============================================================\n",
      "CV_1.pdf: score=0.30 | issues=4\n",
      "CV_2.pdf: score=0.10 | issues=7\n",
      "CV_3.pdf: score=0.40 | issues=3\n",
      "CV_4.pdf: score=0.10 | issues=8\n",
      "CV_5.pdf: score=0.10 | issues=7\n"
     ]
    }
   ],
   "source": [
    "# CV Verification Agent\n",
    "import json\n",
    "import re\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. é‡æ–°èŽ·å– MCP toolsï¼ˆç¡®ä¿è¿žæŽ¥æœ€æ–°ï¼‰\n",
    "# -------------------------------------------------------\n",
    "client = MultiServerMCPClient({\n",
    "    \"social_graph\": {\n",
    "        \"transport\": \"http\",\n",
    "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
    "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
    "    }\n",
    "})\n",
    "mcp_tools = await client.get_tools()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. åˆå§‹åŒ– LLM\n",
    "# -------------------------------------------------------\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    google_api_key=GEMINI_VERTEX_API_KEY,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. æž„å»º ReAct Agent\n",
    "# -------------------------------------------------------\n",
    "agent = create_react_agent(llm, mcp_tools)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. System promptï¼šæŒ‡ç¤º Agent éªŒè¯ CV\n",
    "# -------------------------------------------------------\n",
    "SYSTEM_PROMPT = \"\"\"You are a CV verification specialist for KYC (Know Your Customer) compliance.\n",
    "\n",
    "Your task:\n",
    "1. Extract key information from the provided CV text: name, location, job titles, companies, date ranges, education (school, degree, graduation year), and skills.\n",
    "2. Search for the candidate on LinkedIn using their name and location. Pick the most similar profile (do NOT reject if no exact match).\n",
    "3. Search for the candidate on Facebook using their name. Pick the most similar profile.\n",
    "4. Retrieve the full LinkedIn profile and Facebook profile.\n",
    "5. Compare the CV claims against the social media data. Check for:\n",
    "   - Job title mismatches (e.g., CV says \"Engineer\" but LinkedIn says \"Manager\")\n",
    "   - Company mismatches\n",
    "   - Date/year discrepancies (e.g., impossible overlapping timelines)\n",
    "   - Education mismatches (wrong school, degree, or graduation year)\n",
    "   - Location mismatches\n",
    "   - Skills mismatch (CV claims skills not reflected in LinkedIn)\n",
    "   - Internal inconsistencies in the CV itself (overlapping jobs, future dates, illogical combinations)\n",
    "6. Count the number of discrepancies found.\n",
    "7. At the very end, output a JSON block in this exact format:\n",
    "   {\"score\": <float between 0 and 1>, \"discrepancies\": [\"...\", \"...\"]}\n",
    "\n",
    "   Score guide:\n",
    "   - 1.0 = fully consistent, no issues found\n",
    "   - 0.7-0.9 = minor discrepancies or unverifiable claims\n",
    "   - 0.4-0.6 = notable discrepancies worth flagging\n",
    "   - 0.0-0.3 = major discrepancies or fabricated information\n",
    "\n",
    "Important: Always attempt verification. Treat CV content as ground truth for comparison purposes, but flag inconsistencies between CV and social media data.\"\"\"\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. è¾…åŠ©å‡½æ•°ï¼šå°† contentï¼ˆå¯èƒ½æ˜¯ list æˆ– strï¼‰è½¬ä¸ºçº¯æ–‡æœ¬\n",
    "# -------------------------------------------------------\n",
    "def extract_text(content) -> str:\n",
    "    \"\"\"Convert agent message content to plain string regardless of format.\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    if isinstance(content, list):\n",
    "        parts = []\n",
    "        for block in content:\n",
    "            if isinstance(block, dict) and block.get(\"type\") == \"text\":\n",
    "                parts.append(block[\"text\"])\n",
    "            elif isinstance(block, str):\n",
    "                parts.append(block)\n",
    "        return \"\\n\".join(parts)\n",
    "    return str(content)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. å¯¹æ¯ä»½ CV è¿è¡Œ Agentï¼Œæå– score\n",
    "# -------------------------------------------------------\n",
    "async def verify_cv(cv_text: str, cv_name: str) -> dict:\n",
    "    \"\"\"Run the verification agent on a single CV and return score + reasoning.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Verifying: {cv_name}\")\n",
    "    print('='*60)\n",
    "\n",
    "    user_message = f\"\"\"Please verify the following CV:\n",
    "\n",
    "--- CV START ---\n",
    "{cv_text}\n",
    "--- CV END ---\n",
    "\n",
    "Search for this candidate on LinkedIn and Facebook, retrieve their profiles,\n",
    "and compare with the CV claims. End with a JSON block containing the score and discrepancies.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=SYSTEM_PROMPT),\n",
    "        HumanMessage(content=user_message)\n",
    "    ]\n",
    "\n",
    "    result = await agent.ainvoke({\"messages\": messages})\n",
    "\n",
    "    # â† ä¿®å¤ï¼šç»Ÿä¸€è½¬ä¸ºçº¯å­—ç¬¦ä¸²ï¼Œé¿å… list å¯¼è‡´ re.search æŠ¥é”™\n",
    "    final_message = extract_text(result[\"messages\"][-1].content)\n",
    "\n",
    "    print(f\"\\nAgent response (last message):\\n{final_message}\")\n",
    "\n",
    "    # ä»Ž agent è¾“å‡ºä¸­æå– JSON score\n",
    "    score = 0.5  # default fallback\n",
    "    discrepancies = []\n",
    "\n",
    "    try:\n",
    "        # ä¼˜å…ˆåŒ¹é… ```json ... ``` ä»£ç å—\n",
    "        json_block_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', final_message, re.DOTALL)\n",
    "        if json_block_match:\n",
    "            parsed = json.loads(json_block_match.group(1))\n",
    "        else:\n",
    "            # å¤‡ç”¨ï¼šç›´æŽ¥æœç´¢ {\"score\": ...} ç»“æž„\n",
    "            json_match = re.search(r'\\{\\s*\"score\"\\s*:.*?\\}', final_message, re.DOTALL)\n",
    "            parsed = json.loads(json_match.group()) if json_match else {}\n",
    "\n",
    "        score = float(parsed.get(\"score\", 0.5))\n",
    "        discrepancies = parsed.get(\"discrepancies\", [])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not parse JSON score from agent output: {e}\")\n",
    "        # æœ€ç»ˆå¤‡ç”¨ï¼šç›´æŽ¥ç”¨æ­£åˆ™æå–æ•°å­—\n",
    "        score_match = re.search(r'\"score\"\\s*:\\s*([\\d.]+)', final_message)\n",
    "        if score_match:\n",
    "            score = float(score_match.group(1))\n",
    "\n",
    "    print(f\"\\nâ†’ Final score for {cv_name}: {score}\")\n",
    "    print(f\"â†’ Discrepancies: {discrepancies}\")\n",
    "\n",
    "    return {\n",
    "        \"cv\": cv_name,\n",
    "        \"score\": score,\n",
    "        \"discrepancies\": discrepancies,\n",
    "        \"full_response\": final_message\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7. è¿è¡Œæ‰€æœ‰ 5 ä»½ CV\n",
    "# -------------------------------------------------------\n",
    "verification_results = []\n",
    "\n",
    "for cv_data in all_cvs:\n",
    "    result = await verify_cv(cv_data[\"text\"], cv_data[\"file\"])\n",
    "    verification_results.append(result)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "for r in verification_results:\n",
    "    print(f\"{r['cv']}: score={r['score']:.2f} | issues={len(r['discrepancies'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J14ltXjPtaMF",
    "outputId": "fcb00537-ccce-44e0-a511-de30b73187e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification scores: [0.3, 0.1, 0.4, 0.1, 0.1]\n",
      "{'decisions': [0, 0, 0, 0, 0], 'correct': 2, 'total': 5, 'final_score': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# ä»Ž verification_results æŒ‰ CV æ–‡ä»¶é¡ºåºæå– score\n",
    "scores = [r[\"score\"] for r in sorted(verification_results, key=lambda x: x[\"cv\"])]\n",
    "print(f\"Verification scores: {scores}\")\n",
    "\n",
    "groundtruth = [1, 1, 1, 0, 0]  # Do not modify\n",
    "\n",
    "result = evaluate(scores, groundtruth)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RRbStil_qkQc",
    "kCENjOq6owDd"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

%PDF-1.4
%ï¿½ï¿½ï¿½ï¿½ ReportLab Generated PDF document (opensource)
1 0 obj
<<
/F1 2 0 R /F2 3 0 R /F3 5 0 R /F4 10 0 R
>>
endobj
2 0 obj
<<
/BaseFont /Helvetica /Encoding /WinAnsiEncoding /Name /F1 /Subtype /Type1 /Type /Font
>>
endobj
3 0 obj
<<
/BaseFont /Helvetica-Bold /Encoding /WinAnsiEncoding /Name /F2 /Subtype /Type1 /Type /Font
>>
endobj
4 0 obj
<<
/Contents 15 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
5 0 obj
<<
/BaseFont /Helvetica-Oblique /Encoding /WinAnsiEncoding /Name /F3 /Subtype /Type1 /Type /Font
>>
endobj
6 0 obj
<<
/Contents 16 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
7 0 obj
<<
/Contents 17 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
8 0 obj
<<
/Contents 18 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
9 0 obj
<<
/Contents 19 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
10 0 obj
<<
/BaseFont /Courier /Encoding /WinAnsiEncoding /Name /F4 /Subtype /Type1 /Type /Font
>>
endobj
11 0 obj
<<
/Contents 20 0 R /MediaBox [ 0 0 595.2756 841.8898 ] /Parent 14 0 R /Resources <<
/Font 1 0 R /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ]
>> /Rotate 0 /Trans <<

>> 
  /Type /Page
>>
endobj
12 0 obj
<<
/PageMode /UseNone /Pages 14 0 R /Type /Catalog
>>
endobj
13 0 obj
<<
/Author (\(anonymous\)) /CreationDate (D:20260227145553+00'00') /Creator (\(unspecified\)) /Keywords () /ModDate (D:20260227145553+00'00') /Producer (ReportLab PDF Library - \(opensource\)) 
  /Subject (\(unspecified\)) /Title (\(anonymous\)) /Trapped /False
>>
endobj
14 0 obj
<<
/Count 6 /Kids [ 4 0 R 6 0 R 7 0 R 8 0 R 9 0 R 11 0 R ] /Type /Pages
>>
endobj
15 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 702
>>
stream
Gatm89lJKG'YO<Ebct,hfsfjclrThcOO@;I6<lk:,_j=4N_S&Rca2Z-.8dr*Oel?cG';`d]_)m_J(0Lr)/t_t?&q5Xknmra62Co>C%@WfL\+=EkK(Ga,;`OeQLm-0UCsA=$ujq&p)aq[AIR!P7.SWJSp?P1jWl;MQjtf<67VAA`euUipb\*b,st_5A?/=>BjrqF]0_CV$P#N!?o115A`4pCXmK;fZR)Sg8OGj[U9IhcAj7<pUmGCp>3@0F/*Cn9abhPiiqs#@H&7H*OVc\[JO)"W0/(ai3.6GO-dkq`]d@3jrALF"2fE>#=uboe^L=8G2V9m;9p2=9fGnV/XG&?jisT'<h9r*NCAXu6P9d!O7f1KljZW%<1*>\s6']b(gc[<jCpnNX)SL="/^X>gJVS>u'F>kPl3,rXU\mnOWWs(00V;oPoC<]nigqQZg[+[IXBriZ3k7a3Yuo:^BA2GA'!'<9`=kU&-Gm_KFpN";gYnR<2\EOfgH-r@K/"XQd@(j^\D($?6kVn"X+$"tRrU42YP8(Km&%B_0B'2#NJ&<WBHfY9172XRQl*-D5A`c2EY:g7K+0?rY;O$glhPLg'pHlT#K\m0jh@e\&c[!`\N71oXoOTlaqu/kdA/_i'/O"G)6O1od8TMtq==9c+([S`TASXL4t?-F[+_IdkHWF[#TM%>bImr'6?[m3mluuM]?jtk~>endstream
endobj
16 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 2064
>>
stream
Gatm;D/\/e&H88.EM!GZCG\n,[a7fU\ounmod*(Y@2T8QU2;fOk`SnDn(7"O-/3HTf@^]<YTb*50+[NC4#.05a8BjQ'E'ba+($d4&P_H,Os$I_-2fqhqfKjSQ/aE_A/S$RS>JRjNAKpR3+*oQ1I_D'a&/:'OQ6^X'@Mdpk[[mR:ftV'"QeLY`#0DsJ?IMDMOL.&@O\E-Co[a0VPG$Fa@1_O+cTH\Gs]u@2#Z8koaZJ,*)#iFgc:\K*S1.7(1assOb.S9LA:sJ31Aq#rmb03<Rd6Y/4bsa`_/bPa7O!X2UEOlnbk/jY_s/kL-Eo4`>PI+@pr-]3uUh[JhB76#GL6a(>L+B%0k5lVn0"34Qd+"=B`h3W+7-o0"E:b>#fVo%/on?`OW8>9$iM5[gT<A!*1X>EP$oRFN3;_b9Fqe_m;38=rDCa`E[*('XCk$:Pt%Q)O;1E2?l(o=X=HePg-<Y?T7s8?LgG,Pe*]V<c_CM'9EU>Gdm-E9[XUmi[n3jZd=NH^jeY:]NJJj@H9rQh^crQ9+lsDPWVCqn&=l";0J(CCP?YtHLjUTTrX*\A<j1g"!!.N.qM+?#gV,5<e]U7VqVIdo>0\(acOl%]O>M4a^PUOE'-_]9ZL9kB&?/CY%Ft'Tc*eQ(X)DC`*VhBohe6M4G[+(;9Il]5E6MF93W0-.*`Dk)CBPI`ItObIh/+<DmKZ$G@4.,UC?W<aI*DF:],t#Alg%E<1N(M6Z8-Ye;LNf>2i+'U>4cLpC&o=PVLJ#+3Wl2YD""t5$4%>5oAeTDXE.X=/nR7*F9hm4@o'8Z<][0`Ni@+>-%rJL2>eJs'%[Abj0Q1XP+mWG<Y_9hnF>lP0aCZHcjN\`td48YO)^?f?hd@`f%2M?N+2po=o17**+hln\f?pK<uB5C<oX&>jSqA`V\F,Dl(tKKU_qC*>9,jJD1"BDdi\>*,s+l7kS]Fjja[`qM"AA2l^k.pDqn>=)0&*$1I_]YEW4@@pb'r2Nf8+Pdag:F"<9^lkjcm&]aaE*Ec5k9$-<rMhW?L3OZE'"3qM=[AQ&*FOkHmnH7(Ko53mZh!:84(CF1;"-q<mLfV/;el54^W`ZjW^L"\NSS"-:DLM5%4KZRhHl6c#jL[7DO5K6P(eF)']N=Q(_S*OH^$4T^6+HYL*%W'\3MOUbk"p`_N<nT)OPjt#!$r*XGhWKhHNO<*2?NC&5_-==0M-WhSU9+XSU5#b*Q1^eIG)^!*G]\0aS(@`^:E$GhJ[FSfAtq_cQ^DB/</Ec7BQ`Z89d<cNU-k[b#'h::rp,+E45`>I"1&DG+=L5ZQ2R9@utfmi6Ht+)/,$-J9N%=i?VuP"R.8Gh8Hee">m\uj"YgphCgN&*>ihn,o["4\r!.9nZ#K2rT&'GKt@!L?__AdRVGPC_C5ZE/S23RMV]p6Yfi)$Z@RhdrF&:^;J;"g-!sfqLY.-_[#Tg(-=5$ZU4mbL'UINp\s%<:>"_Mkb<hJsHo21;l1UkOal3?=<>&&%@/1lFFF89g\q3!Y?)Yc#0@nOV<J@GjSrdt\=@t/M2gYAT,@V--m%ALT4<E.oB<L>2(.]WCZVl+-hl%6T947+jXb?)eV)q,dN8A;n$5h98gK7U:Vc<7lO7RNq-?q$Z,>g3,^b4KEKL`iGAc'e<CCJ3&rLH@:.b@U>.HVW%Nl*Oo)]E$mLf\Zm:'E>l&5O3gO[bf-!`R6eGGc#7)9n_;/TSA+F;^iBfg8HA1p.Men$kqO!/;bF>Sqq,Cif%35G^j.54fH?ikeeH>^b1Y@@/QHO=lW=I_k6[mdZe_XXm<b3:C-NnEQ%;%A9jld:LK2&;=>SOgV:#-I^3>rOn(BE@kHC/NGFi1F/X"#KIa:bX#ueW'(9i0Rm?OgdTUj)e-.&<%EeElE?d[[s!$6[b]_hl%V00M&Pt&Y!XKJU-eR$(640o?l%H2*D#B3W6CALKQ'48E!#X#'g$j8MD#`AB4(o<M/)thHiVFOic>P;r&(Z'5P:u2M"MK0k,Xom`T!bp^*nt6LkXtKNZ31^nX3Hq=(n32nFW?lbm:tkiG''<$`n<4?Zeqg*t14-(WB^e)#~>endstream
endobj
17 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 2392
>>
stream
Gau`UD0)1+&H88.Z.#2QEI3P""QC`bH>.HL:1)Erf7%Bo)$7*<K>@_Re@iEmIObFSG&W8@nT6lJ!D0=tmA";9@1!d!W;_fh!.UTVdpi`L_:][(6QA(4%56$#^?s=FVrn]MFf>HakCbY;`GsO(W'pfT!hm'C3!\FG%])?'P<H9Ebqs*QL/Tc_Y,Cd>"=$CofgK?`539c636c@ab[NQTo+_0V_hinB=bK[H(6@G@/"Ab"0"o;$T3G&UXJK,@DQqHf4lQ[g5p2c:Xh_t-]'0@eiNKpgS!\ce:r47-`g[Z;2qhnff08<!n(L$ojnTBm\`Z!p]d)liA_e\L$88^[5ir;r0u;`l8B^6W@HlqI.="'&-I^CAE]rNB0Ufl+7n?7>(O7:K;T+Z-Z'Ypsb%/'`3A'f:1<$;EELrml8N),tI&jJ7#ud3=F-.f;38E_2J<;RHbNugk#"LbHZ!/?g^L0]>&`,-[T`,sIJ766k;TuDd3Fa,#4?nRaYUD5tNNQ3;pu.b&qVAEde0ejV=6=#2Ai@O32_]QDVD(cJKj&Db\qI:!OQKu197EFbn0T]h?HVI,9stR0Sm@7@Wg+>L75AdE['Zr\)CF-g']5`.(?6McAR=Te6("Mcd</#u7J2*CJm@^WD[Bpch'Tjf0eW4SotK0kR<\"?lu/#2^0TT^M<IYrWtUO#Gjue',a(`j[>Qk&+2*.%k5=bPTRa1L(35%"h\kjY:c"W?r?r1"6B4]JUc$61RFk#?7%s2?HrQ\%hM8<1--/KOU:H?Uff[IoX0>DFbC.`<MD1Nu)\H/Z+abmhKg=+N,)e&N$l1$<p,0OL=%SiuKc/$iZU;rU*d$aeJJg<BJ7N*?R!G65=!E*]_'uNh2#U"1fPD3n)#(S]C6W,B4%,rGo3J/<rZo+CMgV*'deFtX\6N^c^`SZa<DJ[>>O7FdGi610^=SI/7UITBJ`,#4IORm70FMGK<NK,TZ:^t!XasNOB/M<>,)d8mn#o&R60Qn,_][r04EQo46K4]RSp6b_&=jO23(\h_Se".'M7=&E?*TGXll`NLVZX#WO<%<N%M<A:6!TC"/6FhZ6=?7\g9Tp]a_L5O&`lH?>Z5\Lga$nIg1$;&/6^O+'3.Jp.;q+?o>OD`:PQ1/L3#>3:k+7>EBMgWs3'?;CUb@>OgrX,.g(t?iLW-L$?N1:q/,[?2i_-BV'ns1<"j!TOZ)T]Jop"meW1efFii!fb[HB28-Qq'M'?POTZ:=__.[(jK*;t?h%RiH@t=e(qnEOImKP4!'EU@o%\%G&3Rh9.%YKTZl=dXfMADsdn=N*$euD3(=.*<%(.ch>=u-BRMR#"`9=YckQqu?EJV!(Pf\bX:AcN]TNK!$l)&34>3&8*`oF+a8U;U!d_hd$+EeP.H[5iGR168e?_"=D9*[`.knVB!;F%RmJKhnPQKsK.++bW^TQR-mW;M>@A:M[3T-Whlk71P)G(#4A*;S/tj\()X=6.0FM"^[?`;(/Ds-S8RNWQN^+&@4NX"M9=(69+`HmcfF&S[&`m2WM#-QsV*)'[++=hr3,M]=.uRmj^?$jK;%/'COV`+4Oc-/<`Y[BL50ZPOL>!O\)4q?K#nuZaETDBOp5YV\8uSU`1Br![2*6EZW23^EfPl/t]DpQ[]%0X'U6_.4`>)Hq2(VXHYD>gtJ9ag/f<L+GG*ZI<_P=mGfXS10`N%mD/Y8FSPYj<31NXGD,'":93&!/2k7rUXUKD!461`qmi@dVd+'lLJZ</E53<f"3+-`W;<lLYc4N2$*:qO*$>8^-LluNQ>8tK^)=6Cqu=R<lOMWkH@m-?bBfp?Fu:3mn=+jTdQo7A*j39(>hi7Y^!B0_FgBQ^a>i]1``]4;b&`&FlC\Cn]WTqOWk^)9qYT#J5]"W=Sc57Y,1@YIEG*KVceTtSQ9du^-o08Xs$T!aWu6AVW5FR>>@U:[bND7O)\_\G8AJIE==O-f[,D1+1P-'(B0,aWl39R2@uo@Xhbu)':Rf7,F8-]1c.KOMBO:;aARl=)AifW,7L!<XK@dD@1rs(UN.lUK`Z)<BEX!^D*W,L$5[\3j;6SPg-."nr`lbuIZeI(U#D+`P<tM?R=8h-$.!<PF>9WZT#a%iuM9mmcU8`sO#%BCKh_hUVmLH>SS*iOHIUCB4Q)qjp@Z9KB/05/"[I@$-aV].o*[S3*c,<lq@fl6\a7W/b$OU80qLshe-plWc4'S!fFfU`r.mQd\[IVu8FR4,&?q?RJDA3#;-Fu6q0'C&+ghFU:[K0$<VZH8?#%o4rBB]D#R@gn9UHG[MWI-BY9@'U)f@eU>m7esKbHA1F@q]f7p5O)hal8<pif*qF]A>SueS<<_?s+!hmTn/D4=+cQ/D&il.Y&+UF*%I]Bs^M4<*D1EPo@bjYWB!cD6WaV>5^L=~>endstream
endobj
18 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 2020
>>
stream
Gau0DD/\/e&H;*)EPOcj.2G[SW42+lj#12s'M*!m!sSi2/^ZHq]qgf2ci8Ga]fWQ8V<JQ,#0hqaF*A/`NhKk=+"]\T#iK_5^Kj^0%-B(5S8akQ^t\\KgPAm$a!Rs+;\"h!&W8Y-Y/=s?%I2U\#W3W7=[9L;.<Qe>O)RnK*.o2"GQbq/M^)JT^r.KP'@B/qiD-7bV0nE+,_jW#gP0us#4o#PJ#.F<_S9Sc\4;LDMZl2\]H7a?e#\'ZgbLu.^QBK0i:FQX>\juQkEK*(1iX)DXET.d48Tu9oM`r#;4<6r1CDS^D&P^<Ga8U+*DGT7$">LH*-NNYF;k>9R,a5XodJcB9cd:W"3=)19^ab/MP$\"K;B!?*>iHlSuVHeVBFg^p%8asdT;i[Q&9?1)9#bL;1r/9bJe"37X?(G\P$2mH=3.9f7En:e:+1$$d<[JD)s;>1]/7fGVp\:lS9.$DM]]HiTtk&2i]Q.^_g>Ra`(M`?(BTL67"gF(&mc?I[9s12=.7`W-2u'O$`*-*9sTS&WMW+aPjR_>+o+^PNc@#<#m)=Cd^=s!>`91_)_e?bI&;URn=pGiJ]RE'V#C,$X@>t<d&Ce=7@5]+0gW!@[@ibZa/d&,nIhlLFY7ODDL(a%Dn&FW/FJBRoMb^rd.>E4G'%`%Fj[ZeRUhDk/mmIXjB&mfp=`0nT4m`jR)9dlibcE8P]o*SXQK;J7sWpLu%7CRV7Bp5dWk`'1>Qu-HZQ)Xj@9GI3,MC?QfZm^-^O$Lsl.ZIBeOJPh%<I7C5Ak&S[*_*S@iqH;XJ6]aBM%H.SkPW(f[+W(U9!iL1)5i+Jeelp,kTdb25o`S8XZMXF6uYb&]ogmPuU4b:_`1P)<IJfU5qC'(P,%+@#'Jm^BJ#u^+Y49I+!So4fR".>.?UZM>a:sXXV/,L*g%bcf?.R*ZWg'F'W+(0\%A4`Z),W-RY*D[?9#M9?=-!#9WHEL3u6HI;!0B/WRkS^H7XR]d*<js6N7<3je@=Mq.]n=Ud>./49J6<Z2-@T0Zc(4m'cus,7,A7m!>+NiF_3b>nP>)Il8EH>ir>Bh(%ZA658KUqnW@]\=T7U.^\,&kO<U%,Gim>-H(6nuY@=ENCkP?SI[#E%/3jea.:H)Eaie6VWQ`6#%oFAJd+%)p2>fQdB!]EpZTo(.T5Do)>jsj]TD47P:VF)lN1$m8(&2f[)]aDXcE0F;#r&cLlCE"V3782][&"u01J2BPLN8MWj4@5q*rq<KPQJ*uJp+7aJfgiVtc#SqbZO:WY*sr`oE4O<V)\MtQA>[_8D455+@_rOcSDU'PEO\"**H"i(08&R-Z;%XJ5imuj1=j^R^'!I'HCo2CDZa6)`(&3s:YTRUS+o0M6EY>c+Au>fEdr-2=2L<I,e;OOq+BV1N^.C:='U?Jr-7?S*9,KC=,<(<H*K*/AA!Ti1l38A]H>F&(9uA-#c'X[`?RQ!mR9j`$0EAugj,<jDNa:a-_dG@DcOM)KN/Xk-?r*oGX'+K?MQo++-Kos+FGp>,Je`u!C%?4j_]kge>!^,>-7:+m2KJfeJUa@0jS6lY,UeK%\Tm(r.K17g3!0g`>c>CM!-Zgk1Laf"0sA!-)S`T1TkO@B^op8IPu>M17LJl$2Z.(?,-;f&C>g+G6,E[!Q0?U1f%Lu;i+HU=JdQMl^Xr\iZ.QlQLnrdWr">#o+*/\4g2*V)q8S4T]L5TI0Ui_/G'=]^ga<8o*3HA)%-Jrq-H^.)p<^P0Zh;$R?5u""Yn1G2En):"GGO]o05N*AuhQ=Uk6??,$kf<8869+J!,k04@_U3+jr(@!VO*flW!0LUW>.Q,f6uXNA"qYNq!h,oJY22+2]R&,5<rpO#"s6nNaC3H#gYqg*5'\Vplc2BFq,m8eu-J4:E%j)RUY0%EeL)N,/l$TJA`sR.^D5?0[#urF9&T5icmrRs)qkdujhHf;bZb2]MAd`[g5Q`8>0,O"nR"',q=:D.oQup!]lEqujk-<q)a#ArGLB7\l/+:"83lL-8f65LP*\X1&1bdD'cQ*1R~>endstream
endobj
19 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 1097
>>
stream
Gau0BgMYb8&:N/3baXj6VFcX]8UX3B)[IRa8Yr:4+J;i!6ZVMS0"nlUUVH7K.FW%$-3T!R!$uZ(kKKGV_Z5(qK'o5\!'fl/k!";<KO"UEj@-<-^tio!1^Qo5e&5H98J"0+c+Q)1'3[oDIQ+@O$174;2+Sk^@9<2-qV@IBgMjS3dM2+RgM-km)ki9L8ddYc\:Q;)Xu+qUP"S1PbeaJ.ZneYc+Ln\D"#I<,(gPNArR(R<JK*M[CkZe8pF#<VJ6C8?i4V5dNK810NCr,97cigZW!-rT/kaP`T_UO)rG2JHIfiC,YZB2Z_D3=l%Jjs]:4oS(%1Yl6#;Se[g5OsQV!2GqDR%]If8Wf7)T.hnR[]c!XBNGqlIH,aK-_28[;F4:>f!,A^k;^cd\,_N1[L;[@)l1W-p0Fa/J2l9aAh!&QJRSZ'Le@.g-0O#bScQ9-[PQ>#,Z1Q+ZL^n=0UYLQcp**.6MZU_=TZKbcfrUAJGe"hFpRoHj(U=('DJI$_&U36RP?kW=$$H[0n5r@q:s[anKMhs3:,*r6,;i6)^k0Z%D5++L+C5RGC^1\DU,WBVmCJ;Gl/`O8s@!F"fFNi37G7?@Qr,hY.A9auDuW'I,#*981dTaHb1>;%>uA2Q&Z=1hT^<"3V`Yh(:@omRddcCW(2qp3=.?(@bl%Y^_'f3Zf\29tVTD(<IQ/cqbGirPiOaV85C[q@N=9_\WPP3k"?MJ&GZW(VM_U@9#tN;__Ra&O>CK%*.68$f,7ZTZpVi]sL9f+?obh&n]mWPd#c-cjjTq@ci#G9[FEXjL=S9,9V^'Tt/N&?gW@4bdWalUTr,>Djb228se15A<:&GctI+\a[2sLF4b*c3L4jsL4]>'+.0\WlFC9c]JW5e]leupU8@n)Z97SoGJ=g8FfY0c[;Wum+M",8KnF.<]F(<FKt+S(`kE[W@@W)0BDda8-@j`/T/<]DbNu`j#6Mg_.W'L$o`UscL-(;JOD/fPQip.b@]eSoRej,X,?2%(dUPm0RP-<ee6Ur)Sd-lQK!NgK3nL)/]$CiNH).'oOBX(iC3E*;W";(tVJd3QJg3e9rO336@`XfJi@$I4(G(lc/]$L$Cn-bt~>endstream
endobj
20 0 obj
<<
/Filter [ /ASCII85Decode /FlateDecode ] /Length 2254
>>
stream
Gau`TgMZ%@&q0LUeD#3LM<QA?]EH:['.49Q3*7OD#$Afpd3;d-@pTj-Bs4eoJ)A`"M^XQ!CM!YO2U"fqG?(1p<NIr'L*(=5-3_fK$i9di'6e/q,47NV/T0e,`Pio8]U'$/-OKqC;^d;Dgb?N-/3BBl38ik:06Dmja,bYo,HB?330TD<E*r\]/e5??,,=)EGNdd/RCBKDWfhg.]$22mQ576ai\RA/BD``*_2fVF1I9ADA:D%-K%Lo-:?W'$8%?D]5Ghf%].!%Y"o1?+K^X22aQ`-Rq4(7+B6O*t+d[<m!AnCO'#p\,F''\I/Y;4th5X=0eSSH$jdMWt,.U`c6h"(;3=39CY@jYpW`GR[<NTpb[8n_6'r_ZXFan]:QCbEp6gM<ubB2Uj/KSrC<4Sl5q2G)b^l)?tGfB1LS+A\"5pW<]EY1]j7ukd0aN%;6JKOGIM.B,BTT:AU2u9.`ZYc0fN!Q/W&TM3ce);$2PXZhGo<=,qpBZk_5-r9NM\3mUE5PlF;e0cIAsY6]8,Z*WQ,-hcjb1MK%I?6epTF;Y%.aZ&)pJ?.RoC]%7agKZ?bcn6!u`@JUGq\F<_7p$+&>V]a;jsDlHLe/Ac?)n`uF//m(Xp=jP4gh84;OZi>tikVS#JV/f8j>WaK.,F'&!OEc^.eK@`V(S/>t`$uF^<cbS_!//WT9f1ul@jkqpG5&Tj<@dBpbnLd9rEtV/*G'N)*&;rHBQWNW'YYPCs^^1maDNMIdOZG,;4ch@XrDE9s<b[lP;L3ig&*A[$q>K(.HX.`kN\(^P^#.N6646^uNc4GmmeFS6oUt6s<tjgIND3tH#mV!2+LH*,f#.$nSSbr!Xu^0T017KdS")Wm8\bmIjQ.cs.'DHUIrc6Y!.[SE2f@Oe3IF).#olTJJ)*n"cO7QB&8sPfh^9QB_#%g'_Lq`so=_B-<%!&0&HW)!oTC2shnH_7He%dTId/qS^i\2hG5"Si[Z[3P]KbB>>fVIOlJCie#=Hjj;aDKFmj6;'4?*uEO)qruiG?QTm!nM3GMF,]c;-lV@/D'l0%gL*:NtUkaGB<U>b$r>A"(0ppd\sWqgTXL+%H/=gO4,=rQdN$[+*F^pT`A!9['8G7>D@q>hFPN-@unn'*jrolZ<GoitC,(`HJl1]hRI'cb@@34o8t`/KsGl,I;<9fGVb91dN>JG("bjXh-4&(%T_SNt2m(d%<h@gHOC'X$<6AeGT8_=7f52_=b%eost@Olb@#6q3I`SEEk,TH&In>(NPoooP/KKlM9!-Ta`oPiOYLl*4e%F=4cc5l1@1VphQ>%YtL_X+*tNWoS%Kq06YA1,ojLras:n"-i&(llheM?o)$VN/h`/1k8teX`6kgt3U:ut2g-c,BP#.@<s==19N-bgHW=^Z/EpVapS&U,OD^7MBt\9Qr.S$KTTsD0$nn&[8]j_1eJsonB$1h@Am:O5jk,LEC!-gq@*lNcC6EF4("-donR#@=h7S7T9:7nc_]'m@PrrLmFQi$,8uc?gg!T<_Rqmt3[Dr0(DJjol0;TNgCF++7"SO3*LP6Qo>cUeh<\0k%=eY&WX'<f.<DEk_95V\iS#h!:l1Z#S+a>RP[B-Au8nB5[PC^*5(4\c<)J<+h[/3h1QrR35p9\1ABs?u:=.*k[ojh<hA-\#ApH,\@J3BKrAs\E!j0e(Ui`PhY['Dt/pga(.P-D44FHU.0hSoKN2OZGuU"Y#&"m0PnW`>4h!$J,78n>!Q"IW4H!!Z("dPum:qiQ\_(.Fos$h5#!TG0G&[?Y<d=Xntf0OS2G$qYa;4GC`_SkFTMoR/^Ue$IP7=rBSoV>"o!!u;1$H9q"?VSVHg>3SM+GZl7&fFhr.Pp*XD*J@rjEk>>W[VM_bO;6S9-d2V&X]M0R2,Dg#DK?%/RtmQlAQ:3raH9)cff;1>eN*dWTkm3Q.KcNk5<p\@YcWkM$r"L:+:W@gfq:rTW][,T[HW3cKu'^(JYGaIkQa>2:gU91j;_3Gr)7A<F(89n#[b&8>MHG]=&69/BOjgFRkmu,;tU=RKOJYJZS?L&RYT[q?rfGk#$";XT%VnH1.CG]E8h5_iN:<7?tQ)OS*A&1XIA=PIP_4?A*["C]Zd%tL!E^0\lO6658:=<A,`LR:r9<BUoq(r>:LL#+>6PG:m!419WhTrB*ZT,'LaPkX3CO=#?>/*rmKmiC.u(;D64ad;H,)YMg$+O_MUB(LK$*1D+oU_?@dMYWlK0F_BTq^(DI]r2D(sj<OJg?:ofjFN&t>C&#%`%o)~>endstream
endobj
xref
0 21
0000000000 65535 f 
0000000061 00000 n 
0000000123 00000 n 
0000000230 00000 n 
0000000342 00000 n 
0000000547 00000 n 
0000000662 00000 n 
0000000867 00000 n 
0000001072 00000 n 
0000001277 00000 n 
0000001482 00000 n 
0000001588 00000 n 
0000001794 00000 n 
0000001864 00000 n 
0000002145 00000 n 
0000002236 00000 n 
0000003029 00000 n 
0000005185 00000 n 
0000007669 00000 n 
0000009781 00000 n 
0000010970 00000 n 
trailer
<<
/ID 
[<d47c95d92d6bdc0410d95f8d19309590><d47c95d92d6bdc0410d95f8d19309590>]
% ReportLab generated PDF document -- digest (opensource)

/Info 13 0 R
/Root 12 0 R
/Size 21
>>
startxref
13316
%%EOF
